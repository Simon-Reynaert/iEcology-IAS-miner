{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c6f6ba",
   "metadata": {},
   "source": [
    "# Join geolocated datasets in LONG format and replace NA's by zero\n",
    "\n",
    "This is the analysis notebook file for joining and creating long formats of all geolocated datamining output files, based on the EASIN introductions past 2016 up until now. \n",
    "\n",
    "### 1. For wikipedia language - based filtering pageviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5aac22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simon\\Documents\\GitHub\\IAScraper\\sample\\dataprocessing\n"
     ]
    }
   ],
   "source": [
    "#Make sure working directtory is set correctly\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785517fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load data\n",
    "\n",
    "wiki_lang = pd.read_csv(\"../../species_pageviews_analysis_2016_present.csv\")\n",
    "\n",
    "uni = pd.read_csv(\"../../UnionList_Species_Traits_85_present.csv\")\n",
    "\n",
    "# Filter introductions from 2016 onwards\n",
    "intro_year = (\n",
    "    uni[uni[\"YEAR\"] >= 2016]\n",
    "    .loc[:, [\"SCIENTIFIC_NAME\", \"COUNTRY\", \"YEAR\", \"WIKI NAME\", \"Group\", \"Habitat\", \"EASIN.ID\"]]\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "# Define language to country mapping\n",
    "lang2country = {\n",
    "    \"en\": [\"UK\", \"IE\"], \"es\": [\"ES\"], \"el\": [\"EL\"], \"fr\": [\"FR\", \"LU\"], \"de\": [\"DE\", \"AT\", \"CH\"],\n",
    "    \"it\": [\"IT\"], \"pt\": [\"PT\"], \"nl\": [\"NL\", \"BE\"], \"sv\": [\"SE\"], \"da\": [\"DK\"], \"fi\": [\"FI\"],\n",
    "    \"cs\": [\"CZ\"], \"hr\": [\"HR\"], \"hu\": [\"HU\"], \"pl\": [\"PL\"], \"ro\": [\"RO\"], \"sk\": [\"SK\"], \"sl\": [\"SI\"],\n",
    "    \"bg\": [\"BG\"], \"et\": [\"EE\"], \"lv\": [\"LV\"], \"lt\": [\"LT\"], \"mt\": [\"MT\"],\n",
    "    \"be\": [\"BE\"], \"at\": [\"AT\"], \"lu\": [\"LU\"], \"cy\": [\"CY\"]\n",
    "}\n",
    "\n",
    "# Explode language-country mapping into rows\n",
    "wiki_lang[\"COUNTRY\"] = wiki_lang[\"Language\"].map(lang2country)\n",
    "wiki_lang = wiki_lang.explode(\"COUNTRY\").dropna(subset=[\"COUNTRY\"])\n",
    "\n",
    "# Join on WIKI NAME and COUNTRY\n",
    "wiki_lang[\"WIKI NAME\"] = wiki_lang[\"Scientific Name\"]\n",
    "wiki_lang2 = wiki_lang.merge(intro_year, how=\"inner\", on=[\"WIKI NAME\", \"COUNTRY\"])\n",
    "\n",
    "# Pivot to long format\n",
    "date_cols = wiki_lang2.columns[wiki_lang2.columns.str.match(r\"^\\d{8}$\")]\n",
    "wiki_lang_long = (\n",
    "    wiki_lang2.melt(id_vars=[\"SCIENTIFIC_NAME\", \"COUNTRY\", \"YEAR\"], \n",
    "             value_vars=date_cols,\n",
    "             var_name=\"date\", value_name=\"views\")\n",
    "    .fillna({\"views\": 0})\n",
    ")\n",
    "\n",
    "# Convert date\n",
    "wiki_lang_long[\"date\"] = pd.to_datetime(wiki_lang_long[\"date\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "wiki_lang_long = wiki_lang_long.dropna(subset=[\"date\"])\n",
    "\n",
    "# Add platform column\n",
    "wiki_lang_long[\"platform\"] = \"wiki_lang\"\n",
    "\n",
    "# Optional: optimize types\n",
    "wiki_lang_long[\"SCIENTIFIC_NAME\"] = wiki_lang_long[\"SCIENTIFIC_NAME\"].astype(\"category\")\n",
    "wiki_lang_long[\"COUNTRY\"] = wiki_lang_long[\"COUNTRY\"].astype(\"category\")\n",
    "wiki_lang_long[\"views\"] = wiki_lang_long[\"views\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bdce0c",
   "metadata": {},
   "source": [
    "### 2. For wikipedia geolocated pageviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99f36761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycountry\n",
    "\n",
    "# Load files\n",
    "uni = pd.read_csv(\"../../UnionList_Species_Traits_85_present.csv\")\n",
    "geo_new = pd.read_csv(\"../../species_pageviews_wiki_geolocated_2023-02-06_now.csv\")\n",
    "geo_old = pd.read_csv(\"../../species_pageviews_wiki_geolocated_2017-02-09_2023-02-05.csv\")\n",
    "\n",
    "# Filter introductions to YEAR >= 2017\n",
    "intro_year_geo = (\n",
    "    uni[uni[\"YEAR\"] >= 2017]\n",
    "    .loc[:, [\"SCIENTIFIC_NAME\", \"COUNTRY\", \"YEAR\", \"Group\", \"Habitat\", \"WIKI NAME\", \"EASIN.ID\"]]\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "# Combine new + old pageviews\n",
    "combined_geo = pd.concat([geo_old, geo_new], ignore_index=True)\n",
    "\n",
    "# Fix EL -> GR and convert ISO2 â†’ full country names\n",
    "def iso2_to_country(iso2):\n",
    "    if iso2 == \"EL\":\n",
    "        iso2 = \"GR\"\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_2=iso2).name\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "intro_year_geo[\"COUNTRY_NAME\"] = intro_year_geo[\"COUNTRY\"].map(iso2_to_country)\n",
    "\n",
    "# Join with combined_geo on Scientific Name + Country\n",
    "filtered_data = combined_geo.merge(\n",
    "    intro_year_geo,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Scientific Name\", \"Country\"],\n",
    "    right_on=[\"WIKI NAME\", \"COUNTRY_NAME\"]\n",
    ")\n",
    "\n",
    "# Melt to long format using all YYYY-MM-DD columns\n",
    "date_cols = filtered_data.columns[filtered_data.columns.str.match(r\"^\\d{4}-\\d{2}-\\d{2}$\")]\n",
    "long_data_geo = filtered_data.melt(\n",
    "    id_vars=[\"SCIENTIFIC_NAME\", \"Country\", \"YEAR\"],\n",
    "    value_vars=date_cols,\n",
    "    var_name=\"date\",\n",
    "    value_name=\"views\"\n",
    ").fillna({\"views\": 0})\n",
    "\n",
    "# Convert and clean date\n",
    "long_data_geo[\"date\"] = pd.to_datetime(long_data_geo[\"date\"], errors=\"coerce\")\n",
    "long_data_geo = long_data_geo.dropna(subset=[\"date\"])\n",
    "long_data_geo[\"views\"] = long_data_geo[\"views\"].astype(int)\n",
    "\n",
    "# Add platform label\n",
    "long_data_geo[\"platform\"] = \"wiki_geo\"\n",
    "\n",
    "# Optional: optimize\n",
    "long_data_geo[\"SCIENTIFIC_NAME\"] = long_data_geo[\"SCIENTIFIC_NAME\"].astype(\"category\")\n",
    "long_data_geo[\"Country\"] = long_data_geo[\"Country\"].astype(\"category\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
